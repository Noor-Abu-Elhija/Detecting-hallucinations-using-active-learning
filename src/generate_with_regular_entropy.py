# scripts/generate_regular_entropy.py
# This script computes the *regular sequence-level entropy* of multiple completions
# generated by Falcon, measuring how uncertain the model’s probability distribution
# is across sampled outputs.

import os, sys, json, datetime
import numpy as np

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
os.environ["TRANSFORMERS_NO_TF"] = "1"

from scripts.generate_answers import load_falcon_model, generate_with_probs, format_prompt
from utils.arg_parser import get_args


def compute_regular_entropy(sequence_probs):
    """
    Compute regular (sequence-level) Shannon entropy.

    Steps:
        1. Convert raw sequence probabilities to a normalized distribution.
        2. Apply H = -∑ p_i * log(p_i) (natural log → nats).

    Args:
        sequence_probs (List[float]): Probabilities for each generated completion.

    Returns:
        tuple:
            float: Entropy in nats.
            list: Normalized probabilities.
    """
    probs = np.asarray(sequence_probs, dtype=np.float64)

    eps = 1e-40  # avoid zeros
    probs = np.clip(probs, eps, 1.0)
    probs = probs / probs.sum()

    entropy = -np.sum(probs * np.log(probs))
    return float(entropy), probs.tolist()


def save_output(question, completions, token_probs, sequence_probs, norm_probs, entropy, output_dir="outputs"):
    """Save all results as a structured JSON file."""
    os.makedirs(output_dir, exist_ok=True)
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(output_dir, f"regular_entropy_{ts}.json")

    data = {
        "question": question,
        "completions": completions,
        "token_probs": token_probs,
        "sequence_probs": sequence_probs,
        "sequence_probs_normalized": norm_probs,
        "regular_entropy_nats": entropy
    }
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"Saved regular entropy output to {path}")


def main():
    args = get_args()
    question = args.question or "What is the capital of France?"
    prompt = format_prompt(question)

    # Step 1: Load Falcon model (CPU mode)
    tokenizer, model = load_falcon_model()

    # Step 2: Generate completions + probabilities
    completions, token_probs, sequence_probs = generate_with_probs(
        prompt=prompt,
        model=model,
        tokenizer=tokenizer,
        num_return_sequences=args.num_generations,
        temperature=args.temperature
    )

    # Step 3: Compute entropy
    H, norm_probs = compute_regular_entropy(sequence_probs)

    print("\n=== Regular Entropy Report ===")
    for i, (c, sp) in enumerate(zip(completions, sequence_probs)):
        print(f"[{i}] p(seq)={sp:.3e}  ->  {c}")
    print(f"\nRegular (sequence) entropy over {len(completions)} samples: {H:.4f} nats\n")

    # Step 4: Save JSON output
    save_output(question, completions, token_probs, sequence_probs, norm_probs, H)


if __name__ == "__main__":
    main()
